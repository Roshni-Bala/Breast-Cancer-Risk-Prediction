# -*- coding: utf-8 -*-
"""risk_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L1cEl88z-ZEdzsKzTkZk207hnPxsKsg2

<h3>Breast Cancer Risk Prediciton</h3>
Data Source: University of California, Irvine (UCI) dataset

importing data with suitable headers
"""

import pandas as pd

titles = ['id',	'diagnosis',	'radius_mean','texture_mean',	'perimeter_mean',	'area_mean',	'smoothness_mean',	'compactness_mean',	'concavity_mean', 'concave_points_mean','symmetry_mean',	'fractal_dimension_mean','radius_stderr', 'texture_stderr', 'perimeter_stderr', 'area_stderr', 'smoothness_stderr', 'compactness_stderr', 'concavity_stderr', 'concave_points_stderr', 'symmetry_stderr', 'fractal_dimension_stderr','radius_w', 'texture_w', 'perimeter_w', 'area_w', 'smoothness_w', 'compactness_w', 'concavity_w', 'concave_points_w', 'symmetry_w', 'fractal_dimension_w']
df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', names=titles)
print(df.shape)
df.head()

"""getting info about data - data type and count of values"""

df.info()

"""describing the data in detail - count, mean, std, max, min, quartiles"""

df.describe()

"""checking for null values if present"""

df.isnull().any()

"""finding unique diagnosis present in dataset"""

df.diagnosis.unique()

"""creating dataframe containing count of each type of diagnosis
<br>
here, B: Benign and M: Malignant
"""

dfgrp = df
df_diagnosis = dfgrp.groupby('diagnosis')
dfdiagsize = df_diagnosis.size()
print(dfdiagsize)

"""finding how much each data attribute is skewed"""

df.skew()



#create 3 different sections (mean, largest (worst), stderr)
df_mean = df.iloc[:,2:12]
df_stderr = df.iloc[:,12:22] 
df_worst =  df.iloc[:,22:32]
# print(df_mean)
# print("**")
# print(df_stderr)
# print("**")
# print(df_worst)

df_mean.hist(bins=10, figsize=(10, 10), color = 'g')

df_worst.hist(bins=10, figsize=(10, 10), color = 'g')

df_stderr.hist(bins=10, figsize=(10, 10), color = 'g', legend=True, grid=True)

"""dataframes including diagnosis column"""

import pandas as pd
df_meanD = pd.DataFrame(df['diagnosis'])
df_meanD = df_meanD.join(df_mean)
df_stderrD = pd.DataFrame(df['diagnosis'])
df_stderrD = df_stderrD.join(df_stderr)
df_worstD = pd.DataFrame(df['diagnosis'])
df_worstD = df_worstD.join(df_worst)

import seaborn as sns
import matplotlib.pyplot as plt
pairgrid = sns.PairGrid(df_meanD, hue='diagnosis')
pairgrid = pairgrid.map_diag(sns.histplot)
pairgrid = pairgrid.map_offdiag(sns.scatterplot)
pairgrid.add_legend()

import numpy as np

corr = df_mean.corr()
mask = np.zeros_like(corr, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True
df1, ax = plt.subplots(figsize=(10, 8))
plt.title('Breast Cancer Feature Correlation')
cmap = sns.diverging_palette(15, 130, as_cmap=True) #custom colourmap
sns.heatmap(corr, vmax=1.2, square='square', cmap=cmap, mask=mask, ax=ax,annot=True, fmt='.3g', linewidths=1)

from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
df_arr = df['diagnosis']
df_arr = labelencoder.fit_transform(df_arr)
df['diagnosis'] = df_arr
df.head()

from sklearn.model_selection import train_test_split
# to find df['diagnosis'] and to use all other attr to predict diagnosis
df_ref = df
#df.head()
df_ref.head()
df_ref = df_ref.drop(columns = ['id', 'diagnosis'])
X = df_ref
print(X.head())
#df_ref.head()
#X = df.to_numpy()
#y = df['diagnosis'].to_numpy()
y = df['diagnosis']
print(y.head())
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=10)
X.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape

"""from here

"""

















"""to here"""

#svm
#decision tree
#k neighbours
#random forest classifier

from sklearn.linear_model import LinearRegression
reg = LinearRegression()
reg.fit(X_train, y_train)

X_test.head()

pred_lm = reg.predict(X_test)
pred_bin_lm = pred_lm
#print(pred_bin_lm)


np.place(pred_bin_lm, pred_bin_lm>=0.5, 1)
np.place(pred_bin_lm, pred_bin_lm<0.5, 0)
#print(pred_bin_lm)
pred_lm = pred_lm.astype(int)
df_pred_lm = pd.DataFrame({'Predicted':pred_lm, 'Actual': y_test})
df_pred_lm.head()

from sklearn import metrics
print("Mean absolute error: ", metrics.mean_absolute_error(y_test, pred_bin_lm))

print("Accuracy:",metrics.accuracy_score(y_test, pred_lm))
print("Precision:",metrics.precision_score(y_test, pred_lm))
print("Recall:",metrics.recall_score(y_test, pred_lm))

from sklearn.metrics import confusion_matrix
labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']
ax= plt.subplot()
confmat = confusion_matrix(y_test, pred_bin_lm)
sns.heatmap(confmat, square = True, annot = True , cmap = 'Greens', fmt = 'd', cbar = True, ax=ax)
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.set_title('Confusion Matrix for Linear Regression')
# x axis - predicted - 0:false ; 1:true
# y axis - actual val- 0:negative ; 1:positive

accuracy_lm = metrics.accuracy_score(y_test, pred_bin_lm)
print("Accuracy of Linear Regression: ", round(accuracy_lm*100, 4), '%')

from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()
logreg.fit(X_train,y_train)
y_pred1=logreg.predict(X_test)

df_logpred = pd.DataFrame({'Predictions': y_pred1, 'Actual': y_test})
(df_logpred.head())

print("Accuracy:",metrics.accuracy_score(y_test, y_pred1))
print("Precision:",metrics.precision_score(y_test, y_pred1))
print("Recall:",metrics.recall_score(y_test, y_pred1))

from sklearn.metrics import confusion_matrix
labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']
ax= plt.subplot()
confmat = confusion_matrix(y_test, y_pred1)
sns.heatmap(confmat, square = True, annot = True , cmap = 'Greens', fmt = 'd', cbar = True, ax=ax)
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.set_title('Confusion Matrix for Logistic Regression')
# x axis - predicted - 0:false ; 1:true
# y axis - actual val- 0:negative ; 1:positive

print("Mean absolute error: ", metrics.mean_absolute_error(y_test, y_pred1))

accuracy_logreg = metrics.accuracy_score(y_test,y_pred1)
print("Accuracy of Logistic Regression: ", round(accuracy_logreg*100, 4), '%')

from sklearn.tree import DecisionTreeRegressor 
regressor = DecisionTreeRegressor(random_state = 0) 
regressor.fit(X_train, y_train)
y_pred2 = regressor.predict(X_test)

y_pred2 = y_pred2.astype(int)
df_decisTree = pd.DataFrame({'Predictions': y_pred2, 'Actual': y_test})
(df_decisTree.head())

print("Accuracy:",metrics.accuracy_score(y_test, y_pred2))
print("Precision:",metrics.precision_score(y_test, y_pred2))
print("Recall:",metrics.recall_score(y_test, y_pred2))

accuracy_dectree = metrics.accuracy_score(y_test,y_pred2)
print("Accuracy of Decision Tree Regression: ", round(accuracy_dectree*100, 4), '%')

from sklearn.metrics import confusion_matrix
labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']
ax= plt.subplot()
confmat = confusion_matrix(y_test, y_pred2)
sns.heatmap(confmat, square = True, annot = True , cmap = 'Greens', fmt = 'd', cbar = True, ax=ax)
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.set_title('Confusion Matrix for Decision Tree Regression')
# x axis - predicted - 0:false ; 1:true
# y axis - actual val- 0:negative ; 1:positive

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators = 100)
rfc.fit(X_train, y_train)
y_pred3 = rfc.predict(X_test)

y_pred3 = y_pred3.astype(int)
df_randtree = pd.DataFrame({'Predictions': y_pred3, 'Actual': y_test})
(df_randtree.head())

print("Accuracy:",metrics.accuracy_score(y_test, y_pred3))
print("Precision:",metrics.precision_score(y_test, y_pred3))
print("Recall:",metrics.recall_score(y_test, y_pred3))

accuracy_randtree = metrics.accuracy_score(y_test,y_pred3)
print("Accuracy of Random Forest Classifier: ", round(accuracy_randtree*100, 4), '%')

from sklearn.metrics import confusion_matrix
labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']
ax= plt.subplot()
confmat = confusion_matrix(y_test, y_pred3)
sns.heatmap(confmat, square = True, annot = True , cmap = 'Greens', fmt = 'd', cbar = True, ax=ax)
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.set_title('Confusion Matrix for Random Tree Classifier')
# x axis - predicted - 0:false ; 1:true
# y axis - actual val- 0:negative ; 1:positive

df_totacc = pd.DataFrame({'Model':['Linear Regression', 'Logistic Regression', 'Decision Tree Regression', 'Random Forest Classification' ], 'Accuracy': [accuracy_lm, accuracy_logreg, accuracy_dectree, accuracy_randtree]})
df_totacc.sort_values('Accuracy')

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(X_train, y_train)
y_pred4 = nb.predict(X_test)

y_pred4 = y_pred4.astype(int)
df_bayes = pd.DataFrame({'Predictions': y_pred4, 'Actual': y_test})
(df_bayes.head())

print("Accuracy:",metrics.accuracy_score(y_test, y_pred4))
print("Precision:",metrics.precision_score(y_test, y_pred4))
print("Recall:",metrics.recall_score(y_test, y_pred4))

accuracy_naiive = metrics.accuracy_score(y_test,y_pred4)
print("Accuracy of Naiive Bayes Classifier: ", round(accuracy_naiive*100, 4), '%')

from sklearn.metrics import confusion_matrix
labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']
ax= plt.subplot()
confmat = confusion_matrix(y_test, y_pred4)
sns.heatmap(confmat, square = True, annot = True , cmap = 'Greens', fmt = 'd', cbar = True, ax=ax)
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.set_title('Confusion Matrix for Naiive Bayes Classifier')
# x axis - predicted - 0:false ; 1:true
# y axis - actual val- 0:negative ; 1:positive

dict1 = {'Model': 'Naiive Bayes Classifier', 'Accuracy': accuracy_naiive}
df_totacc = df_totacc.append(dict1, ignore_index=True)

df_totacc.sort_values('Accuracy')

from sklearn.svm import SVC 
svm = SVC(kernel='linear')
svm.fit(X_train, y_train)
y_pred5 = svm.predict(X_test)

y_pred5 = y_pred5.astype(int)
df_svm = pd.DataFrame({'Predictions': y_pred5, 'Actual': y_test})
(df_svm.head())

print("Accuracy:",metrics.accuracy_score(y_test, y_pred5))
print("Precision:",metrics.precision_score(y_test, y_pred5))
print("Recall:",metrics.recall_score(y_test, y_pred5))


accuracy_svm = metrics.accuracy_score(y_test,y_pred5)
print("Accuracy of Support Vector Machine Classifier: ", round(accuracy_svm*100, 4), '%')

from sklearn.metrics import confusion_matrix
labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']
ax= plt.subplot()
confmat = confusion_matrix(y_test, y_pred5)
sns.heatmap(confmat, square = True, annot = True , cmap = 'Greens', fmt = 'd', cbar = True, ax=ax)
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.set_title('Confusion Matrix for SVM Classifier')
# x axis - predicted - 0:false ; 1:true
# y axis - actual val- 0:negative ; 1:positive

dict2 = {'Model': 'Support Vector Machine Classifier', 'Accuracy': accuracy_svm}
df_totacc = df_totacc.append(dict2, ignore_index=True)
#df_totacc.sort_values('Accuracy')
df_totacc

df_totacc.sort_values('Accuracy')

from sklearn.neighbors import KNeighborsClassifier
neighbors = np.arange(1,100)
train_accuracy = np.empty(len(neighbors))
test_accuracy = np.empty(len(neighbors))
for i, k in enumerate(neighbors):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
  
    train_accuracy[i] = knn.score(X_train, y_train)
    test_accuracy[i] = knn.score(X_test, y_test)

plt.plot(train_accuracy, label='train accuracy')
plt.plot(test_accuracy, label = 'test accuracy')
plt.legend()
plt.show()

knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(X_train, y_train)
y_pred6 = knn.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred6))
print("Precision:",metrics.precision_score(y_test, y_pred6))
print("Recall:",metrics.recall_score(y_test, y_pred6))


accuracy_knn = metrics.accuracy_score(y_test,y_pred6)
print("Accuracy of K-Nearest Neighbours Classifier: ", round(accuracy_knn*100, 4), '%')

dict3 = {'Model': 'K-Nearest Neighbours', 'Accuracy': accuracy_knn}
df_totacc = df_totacc.append(dict3, ignore_index=True)
df_totacc

from sklearn.linear_model import SGDClassifier
sgd = SGDClassifier(loss='hinge', penalty='l2', max_iter=1000)
#hinge - loss function that gives linear SVM
#l2 -> regularlization term used in model (prevents overfitting)
sgd.fit(X_train, y_train)
y_pred7 = sgd.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred7))
print("Precision:",metrics.precision_score(y_test, y_pred7))
print("Recall:",metrics.recall_score(y_test, y_pred7))


accuracy_sgd = metrics.accuracy_score(y_test,y_pred7)
print("Accuracy of Stochastic Gradient Descent: ", round(accuracy_sgd*100, 4), '%')

dict4 = {'Model': 'Stochastic Gradient Descent', 'Accuracy': accuracy_sgd}
df_totacc = df_totacc.append(dict4, ignore_index=True)
df_totacc

#df_totacc = df_totacc.drop([7])

df_totacc.sort_values('Accuracy')

"""start here"""

from sklearn.model_selection import train_test_split
# to find df['diagnosis'] and to use all other attr to predict diagnosis
df_ref = df
#df.head()
df_ref.head()
df_ref = df_ref.drop(columns = ['id', 'diagnosis'])
X = df_ref
print(X.head())
#df_ref.head()
#X = df.to_numpy()
#y = df['diagnosis'].to_numpy()
y = df['diagnosis']
print(y.head())
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=10)
X.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X = sc.fit_transform(X)
from sklearn.decomposition import PCA

pca_t = PCA(n_components = 30)
pca_t.fit_transform(X)

explained_variance = pca_t.explained_variance_ratio_

print(explained_variance)

plt.plot(explained_variance)
plt.ylabel("Eigen Values")
plt.xlabel("Number of Components")
plt.legend(['Eigan Values from Principal Component Analysis'])
plt.show()

new_pca_com = 5
pca = PCA(n_components = new_pca_com)
principalcomps = pca.fit_transform(X)

df_pca = pd.DataFrame(data = principalcomps, columns = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])
df_pca1 = pd.concat([df_pca, df[['diagnosis']]], axis = 1)
df_pca1.head()

print(np.cov(principalcomps.T))
print("**")
#actual eigen values
print(pca.explained_variance_)


print('Explained variation per principal component = ', pca.explained_variance_ratio_)
print('Information loss due to PCA: ', ((1-np.sum(pca.explained_variance_ratio_))*100), '%')

fig = plt.figure(figsize = (5,5))
ax= fig.add_subplot(1,1,1)
ax.set_xlabel('PC1')
ax.set_ylabel('PC2')
ax.set_title('P1 and P2 of 5 Components')
ax.scatter(df_pca1['PC1'][df_pca1['diagnosis']==0], df_pca1['PC2'][df_pca1['diagnosis']==0],c='g', s = 50)
ax.scatter(df_pca1['PC1'][df_pca1['diagnosis']==1], df_pca1['PC2'][df_pca1['diagnosis']==1],c='r', s = 50)
ax.legend(['Benign','Malignant'])
ax.grid()

fig = plt.figure(figsize = (5,5))
ax= fig.add_subplot(1,1,1)
ax.set_xlabel('PC1')
ax.set_ylabel('PC4')
ax.set_title('P1 and P4 of 5 Components')
ax.scatter(df_pca1['PC1'][df_pca1['diagnosis']==0], df_pca1['PC4'][df_pca1['diagnosis']==0],c='g', s = 50)
ax.scatter(df_pca1['PC1'][df_pca1['diagnosis']==1], df_pca1['PC4'][df_pca1['diagnosis']==1],c='r', s = 50)
ax.legend(['Benign','Malignant'])
ax.grid()

fig = plt.figure(figsize = (5,5))
ax= fig.add_subplot(1,1,1)
ax.set_xlabel('PC1')
ax.set_ylabel('PC3')
ax.set_title('P1 and P3 of 5 Components')
ax.scatter(df_pca1['PC1'][df_pca1['diagnosis']==0], df_pca1['PC3'][df_pca1['diagnosis']==0],c='g', s = 50)
ax.scatter(df_pca1['PC1'][df_pca1['diagnosis']==1], df_pca1['PC3'][df_pca1['diagnosis']==1],c='r', s = 50)
ax.legend(['Benign','Malignant'])
ax.grid()

fig = plt.figure(figsize = (5,5))
ax= fig.add_subplot(1,1,1)
ax.set_xlabel('PC1')
ax.set_ylabel('PC5')
ax.set_title('P1 and P5 of 5 Components')
ax.scatter(df_pca1['PC1'][df_pca1['diagnosis']==0], df_pca1['PC5'][df_pca1['diagnosis']==0],c='g', s = 30)
ax.scatter(df_pca1['PC1'][df_pca1['diagnosis']==1], df_pca1['PC5'][df_pca1['diagnosis']==1],c='r', s = 30)
ax.legend(['Benign','Malignant'])
ax.grid()







df_pca

from sklearn.model_selection import train_test_split
X = df_pca
y = df['diagnosis']
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=10)
X.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape

# old test train shapes -> ((569, 30), (398, 30), (398,), (171, 30), (171,))

from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()
logreg.fit(X_train,y_train)
y_pred1=logreg.predict(X_test)
print("Accuracy:",metrics.accuracy_score(y_test, y_pred1))
print("Precision:",metrics.precision_score(y_test, y_pred1))
print("Recall:",metrics.recall_score(y_test, y_pred1))

# original data frame -> PCA -> use the different models -> 
# compare with before_PCA.csv -> optimize

dict1 =  {'Model': 'Logistic Regression', 'Accuracy': metrics.accuracy_score(y_test, y_pred1), 'Precision':metrics.precision_score(y_test, y_pred1), 'Recall':metrics.recall_score(y_test, y_pred1)}
dfppca = pd.DataFrame()
dfppca = dfppca.append(dict1, ignore_index = True)
#df_totacc = df_totacc.append(dict4, ignore_index=True)
dfppca.head()



df_totacc

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators = 100)
rfc.fit(X_train, y_train)
y_pred1 = rfc.predict(X_test)

dict1 =  {'Model': 'Random Forest Classifier', 'Accuracy': metrics.accuracy_score(y_test, y_pred1), 'Precision':metrics.precision_score(y_test, y_pred1), 'Recall':metrics.recall_score(y_test, y_pred1)}
#dfppca = pd.DataFrame()
dfppca = dfppca.append(dict1, ignore_index = True)
#df_totacc = df_totacc.append(dict4, ignore_index=True)
dfppca.head()

from sklearn.linear_model import SGDClassifier
sgd = SGDClassifier(loss='hinge', penalty='l2', max_iter=1000)
#hinge - loss function that gives linear SVM
#l2 -> regularlization term used in model (prevents overfitting)
sgd.fit(X_train, y_train)
y_pred7 = sgd.predict(X_test)
dict1 =  {'Model': 'SGD Classifier', 'Accuracy': metrics.accuracy_score(y_test, y_pred1), 'Precision':metrics.precision_score(y_test, y_pred1), 'Recall':metrics.recall_score(y_test, y_pred1)}
#dfppca = pd.DataFrame()
dfppca = dfppca.append(dict1, ignore_index = True)
#df_totacc = df_totacc.append(dict4, ignore_index=True)
dfppca.head()

dfppca

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(X_train, y_train)
y_pred1 = nb.predict(X_test)
dict1 =  {'Model': 'Naive Bayes Classifier', 'Accuracy': metrics.accuracy_score(y_test, y_pred1), 'Precision':metrics.precision_score(y_test, y_pred1), 'Recall':metrics.recall_score(y_test, y_pred1)}
dfppca = dfppca.append(dict1, ignore_index = True)
dfppca.head()

from sklearn.tree import DecisionTreeRegressor 
regressor = DecisionTreeRegressor(random_state = 0) 
regressor.fit(X_train, y_train)
y_pred1 = regressor.predict(X_test)
dict1 =  {'Model': 'Decision Tree Regression', 'Accuracy': metrics.accuracy_score(y_test, y_pred1), 'Precision':metrics.precision_score(y_test, y_pred1), 'Recall':metrics.recall_score(y_test, y_pred1)}
dfppca = dfppca.append(dict1, ignore_index = True)
dfppca.head()

from sklearn.linear_model import LinearRegression
reg = LinearRegression()
reg.fit(X_train, y_train)
y_pred1 = reg.predict(X_test)

np.place(y_pred1, y_pred1>=0.5, 1)
np.place(y_pred1, y_pred1<0.5, 0)
#print(pred_bin_lm)
y_pred1 = y_pred1.astype(int)

dict1 =  {'Model': 'Linear Regression', 'Accuracy': metrics.accuracy_score(y_test, y_pred1), 'Precision':metrics.precision_score(y_test, y_pred1), 'Recall':metrics.recall_score(y_test, y_pred1)}
dfppca = dfppca.append(dict1, ignore_index = True)
dfppca

from sklearn.svm import SVC 
svm = SVC(kernel='linear')
svm.fit(X_train, y_train)
y_pred1 = svm.predict(X_test)


dict1 =  {'Model': 'SVM', 'Accuracy': metrics.accuracy_score(y_test, y_pred1), 'Precision':metrics.precision_score(y_test, y_pred1), 'Recall':metrics.recall_score(y_test, y_pred1)}
dfppca = dfppca.append(dict1, ignore_index = True)
dfppca

from sklearn.neighbors import KNeighborsClassifier
neighbors = np.arange(1,100)
train_accuracy = np.empty(len(neighbors))
test_accuracy = np.empty(len(neighbors))
for i, k in enumerate(neighbors):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
  
    train_accuracy[i] = knn.score(X_train, y_train)
    test_accuracy[i] = knn.score(X_test, y_test)

x = np.arange(0, 100, 5)
plt.xticks(x)
plt.plot(train_accuracy, label='train accuracy')
plt.plot(test_accuracy, label = 'test accuracy')
plt.legend()
plt.grid(axis='both', which='both')

plt.show()

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)
y_pred1= knn.predict(X_test)

dict1 =  {'Model': 'KNN', 'Accuracy': metrics.accuracy_score(y_test, y_pred1), 'Precision':metrics.precision_score(y_test, y_pred1), 'Recall':metrics.recall_score(y_test, y_pred1)}
dfppca = dfppca.append(dict1, ignore_index = True)
dfppca

"""Metrics before Dimension Reductionality

"""

df_totacc

"""Metrics after Dimension Reductionality

"""

dfppca

